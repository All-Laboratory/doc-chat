# LLM Configuration - Groq First, Together AI Fallback
LLM_PROVIDER=together

# Primary Provider - Groq (FREE, Fast)
GROQ_API_KEY=your_actual_groq_api_key_here
GROQ_MODEL=llama3-8b-8192

# Fallback Provider - Together AI
TOGETHER_API_KEY=d681c57e9e5103697f72eccac56df183b76a1f15dbfbcaf39120dd298dbd7fd1
TOGETHER_MODEL=deepseek-ai/DeepSeek-R1-Distill-Llama-70B

# Database (optional)
# DATABASE_URL=your_postgres_url

# Pinecone (optional)
# PINECONE_API_KEY=your_pinecone_key

# Performance Settings
CHUNK_SIZE=800
CHUNK_OVERLAP=100
TOP_K_RESULTS=3
LOG_LEVEL=WARNING
